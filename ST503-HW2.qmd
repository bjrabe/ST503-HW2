---
title: "ST503-HW3"
format: html
code-overflow: wrap
editor: visual
editor_options: 
  chunk_output_type: console
---

First we load the `faraway` package so we have access to the requisite data sets for the homework.

```{r}
library(faraway)
```

## Problem 1

For this problem, we do exercise 3.4 in LMR. We start by viewing the structure and first few rows of the `sat` data.

```{r}
str(sat)
head(sat)
```

### Part (a)

First we fit a model with total sat score as the response and expend, ratio and salary as predictors.

```{r}
sat_fit_a <- lm(total ~ expend + ratio + salary, data = sat)
sat_fit_a |> summary()
```

We first test the hypothesis that $$\beta_{salary} = 0$$. This is the null hypothesis. Then the alternative hypothesis is $$\beta_{salary} \ne 0$$. We start with the following pivotal quantity which has a t distribution with n-p degrees of freedom:

$$\frac{\hat{\beta}_{salary} - \beta_{salary}}{s.e.(\hat{\beta}_{salary})}$$. To turn the pivotal quantity into a test statistic, we set $$\beta_{salary} = 0$$. This is our null hypothesis. Then our test statistic has the following form: $$\frac{\hat{\beta}_{salary}}{s.e.(\hat{\beta}_{salary})}$$. Since the number of predictors in the model is 3, we have p-1 = 3, so p=4. Since n=50, we have n-p = 50-4 = 46. So our null distribution is $$T \sim t_{n - p} \sim t_{46}$$.

We obtain the estimate and standard error from the model fit summary above. So our test statistic is $$t_{obs} = \frac{\hat{\beta}_{salary}}{s.e.(\hat{\beta}_{salary})} = \frac{-8.823}{4.697} = -1.878$$.

Finally, since our null distribution is $$T \sim t_{46}$$, we have for a two-sided test that our p-value is $$p = 2P(T \ge |t_{obs}|) = 2(1 - P(T < |t_{obs}|))$$ which in R is calculated as follows:

```{r}
2*(1-pt(1.878, 46))
```

We see this p-value matches that given in the summary output for the linear model. At the 0.05 significance level, we fail to reject the null hypothesis that $$\beta_{salary} = 0$$, since the p-value is greater than 0.05. Thus we do NOT have evidence to reject the claim that $$\beta_{salary} = 0$$.

Next we test the null hypothesis that $$\beta_{salary} = \beta_{ratio} = \beta_{expend} = 0$$ versus the alternative hypothesis that at least one of these beta coefficients are non-zero. The test statistic for this test is $$F_{obs} = \frac{MSR}{MSE} = 4.066$$, the last equality following from the output of the model fit summary from above. The null distribution for the test is $$F \sim F_{p-1,n-p}$$. Since we have 3 predictors, p-1 = 3, so p = 4. Thus, n-p = 50-4 = 46. Then the p-value for the test is given by $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$. In R code, we can calculate this as follows:

```{r}
1-pf(4.066, 3, 46)
```

We see this p-value matches that from the model fit summary above. Since the p-value is less than 0.05, we reject the null hypothesis that $$\beta_{salary} = \beta_{ratio} = \beta_{expend} = 0$$ at the 5% significance level, meaning we have evidence that at least one beta parameter (for the predictors) is non-zero.

However, when we look at the p-values for the individual predictors we see that at the 0.05 significance level, we do not have evidence that any of the coefficients are non-zero, suggesting that none of the predictors individually have an effect on the response (in the presence of the other predictors). How is this congruent with the results of the F-test? This is addressed in the Student-to-Student discussion on the Moodle page. It is a consequence of high correlation between the predictors.

### Part (b)

Now we add `takers` to the model from part (a).

```{r}
sat_fit_b <- lm(total ~ expend + ratio + salary + takers, data = sat)
sat_fit_b |> summary()
```

We want to test the null hypothesis that $$\beta_{takers} = 0$$, versus the alternative hypothesis that $$\beta_{takers} \ne 0$$. Then the test statistic is $$\frac{\hat{\beta}_{takers}}{s.e.(\hat{\beta}_{takers})}$$. The null distribution is $$T \sim t_{n-p}$$. Since the model has 4 predictors, p-1 = 4, so p = 5. Hence n-p = 50-5 = 45. We obtain the observed value of the test statistic to be -12.559 from the model fit summary above. Then the p-value for a two-sided test of the null hypothesis is given by $$p = 2P(T \ge |t_{obs}|) = 2(1 - P(T < |t_{obs}|))$$, which we can calculate in R as follows:

```{r}
2*(1-pt(abs(-12.559), 45))
```

We see the calculated p-value (2.220446e-16) is very close to that provided in the model fit summary above (2.61e-16). The slight difference is likely due to differences in how floating point arithmetic is handled between our calculation and the `lm` function. Since our p-value is much less than 0.05, we reject the null hypothesis at the 5% significance level. That is, we have evidence that the true value of $$\beta_{takers}$$ is non-zero. 

Next we wish to compare this model to the model in part (a) using an F-test. The null hypothesis is that the model in part (a), the reduced model, explains the same amount of variability in the response as the model in part (b) (the full model) does. Let $$SSE_{k}$$ denote the sum of squared errors for model k, where k takes value a for the reduced model and b for the full model. Then our test statistic is $$F_{obs} = \frac{\frac{SSE_a - SSE_b}{q}}{\frac{SSE_b}{n - p}}$$, where q is the difference in dimension between the two models, which is q=1 in this case, and n and p are chosen from the full model. We calculate the value of the F-statistic:

```{r}
SSE_a <- t(sat_fit_a$residuals)%*%sat_fit_a$residuals
SSE_b <- t(sat_fit_b$residuals)%*%sat_fit_b$residuals
F_obs <- ((SSE_a - SSE_b)/1)/(SSE_b/45)
F_obs
```

Then since the null distribution is $$F \sim F_{q,n - p}$$, where q=1 and n-p=45, the p-value for the test is $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$. We calculate this as follows:

```{r}
1-pf(157.74, 1, 45)
```

We can compare our results with the output of an F-test using R code:

```{r}
anova(sat_fit_a, sat_fit_b)
```

We see that our calculated F-statistic matches that provided in the `anova` function output. Our calculated p-value is very close to that provided in the `anova` function output, the tiny difference likely being a consequence of how floating point arithmetic is handled by our calculation versus the `anova` function. Since the p-value is much less than 0.05, we have evidence against the null hypothesis at the 0.05 significance level. That is, we have evidence that the full model in part (b) explains more of the variability in the response than the reduced model in part (a) does.

Finally, to demonstrate the equivalence of the F-test and t-test in this case, note that the t-statistic of -12.559 from the full model, when squared, equals (roughly, due to rounding) the F-statistic of 157.74 obtained when comparing the reduced and full models. As discussed in the lecture, this is in general the case when the reduced model is formed by putting exactly one $$\beta_{k} = 0$$. We also see that the p-values are identical for the two tests. We can understand the equivalence of the two tests by considering the null hypothesis in the t-test: $$\beta_{takers} = 0$$. If we assume this hypothesis is true, it is the same as imposing a linear constraint on the full model to form a reduced model, which can then be compared with the full model using a general F-test. If we reject the null using the F-test, then the model which includes `takers` explains more variability in the response than the model that does not include `takers`, meaning $$\beta_{takers}$$ is not likely to be 0. This is equivalent to rejecting the null hypothesis $$\beta_{takers} = 0$$ of the t-test for the coefficient of `takers`. 

## Problem 3

For this problem, we do exercise 3.6 in LMR. We use the `happy` data set. We start by viewing its structure and first few rows.

```{r}
str(happy)
head(happy)
```

Now we fit a regression model with `happy` as the response and the other four variables as predictors.

```{r}
lm_fit_happy <- lm(happy ~., data = happy)
lm_fit_happy |> summary()
```

### Part (a)

We see from the model fit summary output that `love` is the only significant predictor at the 1% level.

### Part (b)

Now we use the `table` function to produce a numerical summary of the response.

```{r}
table(happy$happy) 
```

We see there are more values at the high end of the happiness scale. In other words, the distribution is left-skewed. So the assumption that the response is normally distributed is questionable. And the response not being normally distributed implies the errors are not normally distributed. This follows from the logically equivalent contrapositive statement that normally distributed errors implies normally distributed response, which we showed in lecture. Thus the assumption of normality of errors, which is needed for a valid t-test, may be violated.

### Part (c)

Now we use the permutation test to test the significance of the `money` predictor. Our null hypothesis is $$\beta_{money} = 0$$, versus the alternative hypothesis $$\beta_{money} \ne 0$$. Our observed test statistic is the usual t-test test statistic $$\frac{\hat{\beta}_{money}}{s.e.(\hat{\beta}_{money})}$$. Since this is a permutation test, we use computation to determine the null distribution (of the t-statistic), rather than the normal theory based approach we have used in previous problems. Then from this empirical distribution and our observed value for the test statistic we calculate the p-value. 

```{r}
###Set seed for reproducibility
set.seed(123)

###Specify number of permutations to be done
n = 10000

### Initialize vector to store empirical null t-statistic values
t_money <- rep(NA, n)

### Calculate empirical null values of t-statistic by permuting the money predictor and update the above empirical null t-statistic vector
for (i in 1:n){
  lm_fit <- lm(happy ~ sample(money) + sex + love + work, data = happy)
  t_money[i] <- summary(lm_fit)$coefficients[2,3]
}

###calculate the p-value 
mean(abs(t_money) > abs(summary(lm_fit_happy)$coefficients[2,3]))
```

We see that our p-value from the permutation test exceeds 0.05, so we fail to reject the null hypothesis at the 5% significance level. That is, we do NOT have evidence that $$\beta_{money}$$ is non-zero. 

### Part (d)

Here we plot a histogram of the permutation t-statistics.

```{r}
hist(t_money, freq = FALSE)
```

### Part (e)

Here we overlay a t-density over the histogram. Note n=39 and p-1=4, so n-p = 39-5 = 34

```{r}
grid <- seq(-3, 3, length = 300)
hist(t_money, freq = FALSE)
lines(grid, dt(grid, 34))
```

We see that the empirical null distribution of the t-statistic that we calculated by permutation (demonstrated by the underlying histogram) matches well with the expected null distribution (based on theory of normal errors), which is a t-distribution with 34 degrees of freedom.

### Part (f)

Now we use a nonparametric bootstrap procedure to determine the 90% and 95% confidence intervals for $$\beta_{money}$$.

```{r}
###set number of bootstrap resamples
B <- 10000

# Initialize a vector to store bootstrap estimates for beta_money
beta_money_boot <- rep(NA, B)

# create bootstrap resample estimates for beta_money and update the above vector
for (i in 1:B){
  resampled_residuals <- sample(lm_fit_happy$residuals, replace = TRUE)
  y_boot <- lm_fit_happy$fitted.values + resampled_residuals
  lm_fit <- lm(y_boot ~ money + sex + love + work, data = happy)
  beta_money_boot[i] <- lm_fit$coefficients['money']
}

# determine 90% CI
CI_90_boot <- quantile(beta_money_boot, c(0.05, 0.95))

# determine 95% CI
CI_95_boot <- quantile(beta_money_boot, c(0.025, 0.975))

#print
CI_90_boot
CI_95_boot

```

We can compare this with the 90% and 95% CIs obtained from the theory of assuming normally distributed errors.

```{r}
CI_90_t <- confint(lm_fit_happy, level = 0.9)[2,]
CI_95_t <- confint(lm_fit_happy)[2,]

CI_90_boot
CI_90_t
CI_95_boot
CI_95_t
```

We see the intervals obtained from the theory of assuming normally distributed errors are similar to those obtained with the bootstrap, with the bootstrap intervals being slightly narrower, as was the case for the examples in the lecture.

We see that for both the normal-error based 90% CI and the bootstrap 90% CI, 0 falls outside the intervals. Therefore we reject the null hypothesis $$\beta_{money} = 0$$ at the 10% level. This is consistent with both the normal-error based p-value for `money` and the permutation test.  

The results however are discrepant for the 95% CI. The bootstrap 95% CI also doesn't contain 0, so we would reject the null hypothesis $$\beta_{money} = 0$$ at the 5% level if we were using this confidence interval. This is in contrast to the normal-error based 95% CI, where 0 is in the interval. In this case, we would fail to reject the null hypothesis. This latter conclusion is consistent with both the normal-error based p-value for `money` (provided in the model fit summary output) and the permutation test.


## Problem 4

Here we do exercise 3.7 in LMR. We are using the `punting` data. We start by viewing the structure of the data set and the first few rows.

```{r}
str(punting)
head(punting)
```

### Part (a)

We fit a regression model with `Distance` as the response and right and left leg strength and flexibility as predictors.

```{r}
lm_fit_punting <- lm(Distance ~ RStr + LStr + RFlex + LFlex, data = punting)
lm_fit_punting |> summary()
```

We see from the output that at the 5% significance level, none of the predictors are significant (all of their p-values exceed 0.05).

### Part (b)

To do an F-test, we have the null hypothesis $$\beta_{RStr} = \beta_{LStr} = \beta_{RFlex} = \beta_{LFlex} = 0$$ versus the alternative hypothesis that at least one beta parameter is non-zero. Our F-statistic is then $$F_{obs} = \frac{MSR}{MSE} = 5.59$$, the latter equality coming from the output from the model fit summary above. Now the null distribution is $$F \sim F_{p - 1, n - p}$$, where in this case n is 13 and p-1 = 4, so p = 5. Thus n-p = 13-5 = 8. So our p-value is $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$, which we calculate in R as follows:

```{r}
1-pf(5.59, 4, 8)
```

We see this p-value matches that provided for the F-test in the summary output above. Since the p-value is less than 0.05, we reject the null hypothesis at the 5% significance level. That is, we have evidence that at least one beta parameter is non-zero (or alternatively, that collectively these 4 parameters have a relationship with the response).

However, note that none of the predictors are individually significant at the 5% level, as we noted above. This is a situation analogous to that discussed in problem 1 and is a consequence of the correlation between the predictor variables.

### Part (c)
Our null hypothesis for this test is $$\beta_{RStr} = \beta_{LStr}$$, and our alternative hypothesis is that $$\beta_{RStr} \ne \beta_{LStr}$$. To conduct this test, we note that $$\beta_{RStr} = \beta_{LStr}$$ is a linear constraint, so we can fit a reduced model with this constraint and compare it to the full model from part (a) using the general F-test. The F-statistic has the form $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q is the difference in dimension between the full model and reduced model, and n,p comes from the full model. Since we have a single linear constraint $$\beta_{RStr} = \beta_{LStr}$$, we conclude q=1. And from part (b) we have n-p = 8. So the null distribution is $$F \sim F_{q, n - p} \sim F_{1,8}$$. We can determine the value of the F-statistic by fitting the reduced model and using the `anova` function to compare the reduced and full models.

```{r}
lm_fit_punting_reduced_c <- lm(Distance ~ I(RStr + LStr) + RFlex + LFlex, data = punting)
lm_fit_punting_reduced_c |> summary()
anova(lm_fit_punting_reduced_c, lm_fit_punting)
```

From the output, we see the F-statistic is 0.5804. So we can determine the p-value using $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$, which is calculated as:

```{r}
1-pf(0.5804, 1, 8)
```

The calculated p-value agrees with the one in the `anova` function output. Since the p-value is greater than 0.05, we fail to reject the null hypothesis at the 5% significance level. That is, we do not have evidence that the full model explains more variability in the response than the reduced model does. So we fail to reject the supposition that the right and left leg strength have the same effect. 

### Part (d)

Now we construct a 95% confidence region for $$(\beta_{RStr}, \beta_{LStr})$$. To visualize this region, we use the `ellipse` package.

```{r}
library(ellipse)
plot(ellipse(lm_fit_punting, c(2,3)), type = 'l')
points(coef(lm_fit_punting)[2], coef(lm_fit_punting)[3], pch = 19)
```

The confidence region represents a range of plausible values for $$(\beta_{RStr}, \beta_{LStr})$$. From part (c), we cannot reject the hypothesis that $$\beta_{RStr} = \beta_{LStr}$$. Thus we expect points of the form $$(\beta_{RStr}, \beta_{RStr})$$ to lie within the confidence ellipse, as these represent the case where $$\beta_{RStr} = \beta_{LStr}$$. To visualize this, we can overlay the line y = x onto the confidence ellipse.

```{r}
library(ellipse)
plot(ellipse(lm_fit_punting, c(2,3)), type = 'l')
points(coef(lm_fit_punting)[2], coef(lm_fit_punting)[3], pch = 19)
abline(0, 1)
```

We see that the line intersects many points of the ellipse, as expected.

### Part (e)
Next we fit two models to test the hypothesis that it is total leg strength defined by adding the right and left leg strengths that is sufficient to predict the response in comparison to using individual left and right leg strengths. The individual model has the form $$Distance = \beta_o + \beta_{RStr}(RStr) + \beta_{LStr}(LStr) + \epsilon$$. Thus the total leg strength model is a reduced form of the individual model with $$\beta_{RStr} = \beta_{LStr}$$. Then the null hypothesis is that our reduced model (total leg strength model) explains the same amount of variability in the response as the full model (individual leg model). As with any general F-test, the test statistic has the form $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q is the difference in dimension between the full model and reduced model, and n,p comes from the full model. Since we have one linear constraint to form the reduced model, namely $$\beta_{RStr} = \beta_{LStr}$$, we conclude that q=1. The full model has two predictors so p-1 = 2, meaning p=3. And n=13, so n-p = 13-3 = 10. Thus the null distribution is $$F \sim F_{q, n - p} \sim F_{1,10}$$. To obtain the F-statistic, we fit both models and use the `anova` function.

```{r}
lm_fit_punting_sum <- lm(Distance ~ I(RStr + LStr), data = punting)
lm_fit_punting_individual <- lm(Distance ~ RStr + LStr, data = punting)
anova(lm_fit_punting_sum, lm_fit_punting_individual)
```

From the `anova` function output we have an F-statistic of 0.2969. So our p-value has the form $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$, which we calculate by:

```{r}
1-pf(0.2969, 1, 10)
```

We see that the output from our calculation agrees with the p-value in the`anova` function output. We get a p-value (0.5978) for this general F-test much larger than 0.05 so we fail to reject the null hypothesis at the 5% significance level. That is, we do NOT have evidence that the model with individual leg strengths as predictors explains more variability in the response than the model which considers only the sum of the left and right leg strengths. Thus the reduced model (the total leg strength model) seems sufficient to predict the response. 

### Part (f)
Our null hypothesis for this test is $$\beta_{RFlex} = \beta_{LFlex}$$, and our alternative hypothesis is that $$\beta_{RFlex} \ne \beta_{LFlex}$$. To conduct this test, we note that $$\beta_{RFlex} = \beta_{LFlex}$$ is a linear constraint on the full model in part (a), so we can fit a reduced model with this constraint and compare it to the full model from part (a) using the general F-test. The F-statistic has the form $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q is the difference in dimension between the full model and reduced model, and n,p comes from the full model. Since we have a single linear constraint $$\beta_{RFlex} = \beta_{LFlex}$$, we conclude q=1. And from part (b) we have n-p = 8. So the null distribution is $$F \sim F_{q, n - p} \sim F_{1,8}$$. We can determine the value of the F-statistic by fitting the reduced model and using the `anova` function to compare the reduced and full models.

```{r}
lm_fit_punting_reduced_f <- lm(Distance ~ RStr + LStr + I(RFlex + LFlex), data = punting)
lm_fit_punting_reduced_f |> summary()
anova(lm_fit_punting_reduced_f, lm_fit_punting)
```

We see from the `anova` function output that the F-statistic is 1.9346. So we calculate the p-value the same way as we did in part (c) (modifying the value of the test statistic of course):

```{r}
1-pf(1.9346, 1, 8)
```

We see the calculated p-value matches that in the `anova` function output. This p-value exceeds 0.05, so we fail to reject the null hypothesis at the 5% significance level. That is, we do NOT have evidence that the right and left leg flexibilities have different effects. 

### Part (g)
In this part we take simultaneously the null hypotheses from parts (c) and (f). That is, our null hypothesis is $$\beta_{RStr} = \beta_{LStr}$$ and $$\beta_{RFlex} = \beta_{LFlex}$$. Our alternative hypothesis is that at least one of the equalities in the null hypothesis is false. To test the hypothesis, we can consider a reduced model of the full model in part (a), where the constraints are $$\beta_{RStr} = \beta_{LStr}$$ and $$\beta_{RFlex} = \beta_{LFlex}$$, from the null hypothesis. As always the F-statistic is $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q is the difference in dimension between the full model and reduced model, and n,p comes from the full model. Since we have two linear constraints, q=2. And n-p = 8 (from part (b)). So the null distribution of the test is $$F \sim F_{q, n - p} \sim F_{2, 8}$$. To determine the value of the F-statistic, we can fit the reduced model and compare it with the full model using the `anova` function.

```{r}
lm_fit_punting_reduced_g <- lm(Distance ~ I(RStr + LStr) + I(RFlex + LFlex), data = punting)
lm_fit_punting_reduced_g |> summary()
anova(lm_fit_punting_reduced_g, lm_fit_punting)
```

We see from the output that the value of the F-statistic is 1.25. So the p-value (calculated the same as in parts (c) and (f) with the value of the test statistic and q changed) is:

```{r}
1-pf(1.25, 2, 8)
```

The calculated p-value matches the p-value in the `anova` function output. This p-value is larger than 0.05. Thus, we fail to reject the null hypothesis at the 5% significance level. That is, we do not have evidence for asymmetry in leg strength or flexibility. 

### Part (h)
Here we fit a model with `Hang` as the response and the same four predictors.

```{r}
lm_fit_punting_hang <- lm(Hang ~ RStr + LStr + RFlex + LFlex, data = punting)
lm_fit_punting_hang |> summary()
```

We have not discussed a test which allows us to compare this model to that in (a). The general F-test assumes one model in the comparison is a nested model of the other and has the same response variable. This is clearly not the case for this model relative to that in part (a), so we cannot use the general F-test as discussed. 


## Problem 5
For this problem we do exercise 4.1 in LMR. For this question we use the `prostate` data. We start by viewing the structure of the data set and the first few rows.

```{r}
str(prostate)
head(prostate)
```

Now we fit a model with `lpsa` as the response and the other variables as predictors.

```{r}
lm_fit_prostate <- lm(lpsa ~., data = prostate)
lm_fit_prostate |> summary()
```

### Part (a)
For this part, we are given the values for a new patient. We store them in a data frame.

```{r}
new_data <- data.frame('lcavol' = 1.44692, 'lweight' = 3.62301, 'age' = 65.00000, 'lbph' = 0.30010, 'svi' = 0.00000, 'lcp' = -0.79851, 'gleason' = 7.00000, 'pgg45' = 15.00000)
```

Let $$c^* = (1, lcavol^*, lweight^*, ..., pgg45^*)^T$$, where the * represents the value of a predictor for the new patient, and $$\hat{\beta}$$ is the p-vector of estimates for the coefficients of the model. Then our point estimate for `lpsa` for this new patient is $$\hat{Y}^* = (c^*)^T\hat{\beta}$$. We calculate this with the `predict` function:

```{r}
predict(lm_fit_prostate, newdata = new_data)
```

So the predicted `lpsa` for this patient is 2.389053. Now we estimate the 95% CI of the predicted `lpsa` for this patient, which is commonly called the prediction interval. The formula for this interval is based on the distribution of the following pivotal quantity $$\frac{\hat{Y}^* - Y^*}
{\hat{\sigma}\sqrt{1 + (c^*)^T(X^TX)^{-1}(c^*)}} \sim t_{n - p}$$. From this distribution we can determine the 95% CI (prediction interval). We can calculate it with the `predict` function.

```{r}
predict(lm_fit_prostate, newdata = new_data, interval = 'prediction', level = 0.95)
```

So the 95% CI/prediction interval for the new value of `lpsa` is (0.9646584, 3.813447).

### Part (b)
Now we repeat the last question for a patient with the same values except that he is age 20. First we update the `new_data` data frame and then we recalculate the point and interval estimates.

```{r}
new_data_updated <- new_data
new_data_updated$age <- 20
predict(lm_fit_prostate, newdata = new_data_updated, interval = 'prediction', level = 0.95)
```

The confidence interval is wider because an age of 20 is further from the mean age (63.86598) than the original age of 65 is. This leads to more variability in the response variable so the prediction interval is wider. 

### Part (c)
Now we take the model and remove all the predictors that are not significant at the 5% level.

```{r}
lm_fit_prostate |> summary()
```

The predictors which are significant at the 5% level are `lcavol`, `lweight`, and `svi`, so we refit the model with only these predictors.

```{r}
lm_fit_prostate_refit <- lm(lpsa ~ lcavol + lweight + svi, data = prostate)
lm_fit_prostate_refit |> summary()
```

Now we use the new model to recompute the predictions of the previous question. It doesn't matter which age we use since age is not a predictor in the model. 

```{r}
predict(lm_fit_prostate_refit, newdata = new_data, interval = 'prediction', level = 0.95)
```


The width of the confidence interval is 3.806724 - 0.9383436 = 2.8683804.

Compare this with the original models where the width of the confidence intervals were 3.813447 - 0.9646584 = 2.8487886 (part (a)) and 5.006707 - 1.538744 = 3.467963 (part (b)). 

The CI of the reduced model is very slightly wider than that for the prediction made by the full model using age 65, but the CI of the reduced model is quite smaller than the CI for the prediction made by the full model using age 20. Thus from the perspective of confidence interval widths, the reduced model may be preferable. However, we may lose valuable prediction information when eliminating predictors. An F-test would be enlightening to compare the models. 


## Problem 6
To get this problem started, we first need run the code to create the function `ftest`. This is copied from the Moodle page.

```{r}
ftest = function(model, A, b = 0)
  # General linear test of H0: A beta = b
  # model is the fitted model under H1 
  # A needs to be of full rank
{
  BetaHat = coef(model)
  dimA = dim(A)
  if(length(BetaHat) != dimA[2]) stop("Sizes of A and Beta are incompatible")
  q = dimA[1]
  if(qr(A)$rank != q) stop("Rows of A must be linearly independent.")
  out = numeric(4)
  names(out) = c("F","df1","df2","p-value")
  dfe = df.residual(model)
  diff = A%*%BetaHat - b
  fstat = t(diff) %*% solve(A%*%vcov(model)%*%t(A)) %*% diff / q
  # Note vcov = MSE * XtXinv
  fstat = as.numeric(fstat)
  out[1] = fstat
  out[2] = q
  out[3] = dfe
  out[4] = 1 - pf(fstat, q, dfe)
  return(out)
} # End of function ftest
```

### Part (a)
Here we conduct the overall F-test. The null hypothesis is $$\beta_{status} = \beta_{income} = \beta_{verbal} = 0$$, and the alternative hypothesis is that at least one beta parameter is nonzero. We fit the model. 

```{r}
lm_fit_gamble <- lm(gamble ~ status + income + verbal, data=teengamb)
lm_fit_gamble |> summary()
```

We could calculate the F-statistic ourselves from the data if we wanted to by finding MSR and MSE and taking the ratio, but here we take it from the model fit summary output instead. So the F-statistic is $$F_{obs} = \frac{MSR}{MSE} = 11.49$$, the latter equality coming from the output of the model fit summary. The null distribution is $$F \sim F_{p - 1, n - p}$$ where p-1 is the number of predictors. Thus p-1=3, so p=4 and n-p equals 47-4=43. Hence we can calculate the p-value by taking $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$. In R this is calculated as follows: 

```{r}
1-pf(11.49, 3, 43)
```

We see that the p-value we calculated agrees with that provided in the output of the model fit summary. Since our p-value is less than 0.05, we reject the null hypothesis at the 5% significance level. That is, we have evidence against the null hypothesis, meaning we have reason to believe that at least one of the beta parameters (for the predictors) is non-zero. 

### Part (b)
Here we test the null hypothesis $$\beta_2 = \beta_{income} = 3$$ versus the alternative hypothesis $$\beta_2 = \beta_{income} \ne 3$$. Since we wish to use the function `ftest`, we need to reframe this test as comparing a reduced model to a full model. Since we want $$\beta_2 = \beta_{income} = 3$$, we can consider this equality to be a single linear constraint. Then our A matrix is $$A = \begin{pmatrix}
0 & 0 & 1 & 0
\end{pmatrix}$$, and our b vector is $$b = \begin{pmatrix}
3
\end{pmatrix}$$.

We plug A and b, along with the fit for the full model, into the `ftest` function to compare the reduced model with the full model, which is equivalent to the t-test if we constrain one parameter to be a constant. 

```{r}
ftest(lm_fit_gamble, matrix(c(0,0,1,0), nrow = 1, ncol = 4), b = 3)
```

The p-value we obtain from the `ftest` output matches exactly that found using a t-test in the document ST503R-3. Since our p-value is less than 0.05, we have evidence against the null hypothesis at the 5% significance level. That is, our evidence favors the alternative hypothesis $$\beta_2 = \beta_{income} \ne 3$$. 

### Part (c)
Here we need to import the surgical survival data.

```{r}
surgery <- read.table('surgical_unit_data.txt', header = FALSE, col.names = c('blood_clot', 'PI', 'enzy', 'liver', 'age', 'gender',
'mod_use', 'heavy_use', 'sur_time', 'ln_sur_time'))
```

We start by viewing the structure of the data set and the first few rows.

```{r}
str(surgery)
head(surgery)
```

Now we fit the full model and carry out the overall F-test. From the ST503R-3 document, the predictors to be used in the full model include `blood_clot`, `PI`, `enzy`, `liver`, and `age`. The null hypothesis for the overall F-test is $$\beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = 0$$. The alternative hypothesis is that at least one of these beta parameters is non-zero. 

```{r}
lm_fit_surgery <- lm(sur_time ~ blood_clot + PI+ enzy + liver + age, data = surgery)
lm_fit_surgery |> summary()
```

We could calculate the F-statistic for the test by calculating MSR and MSE from the data and taking their ratio. Instead, we will take the value for the F-statistic from the model fit summary output. The F-statistic is $$F_{obs} = \frac{MSR}{MSE} = 21.87$$, the latter equality coming from the model fit summary output. The null distribution is $$F \sim F_{p - 1, n - p}$$, where p-1=5 (the number of predictors), so p=6. Thus n-p = 54 - 6 = 48. We can then calculate the p-value as follows: $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$, which in R is calculated as follows:

```{r}
1 - pf(21.87, 5, 48)
```

We see this p-value roughly agrees with that provided in the model fit summary output, the slight difference likely do to differences in floating point arithmetic. Since the p-value is much smaller than 0.05, at the 5% significance level we have evidence against the null hypothesis (so we reject it). That is, we have reason to believe that at least one of the beta parameters (for the predictors) is non-zero. 

### Part (d)
Now we are interested in a reduced model where $$\beta_4 = \beta_5 = 0$$. And our null hypothesis is that the reduced model explains as much variability in the response `sur_time` as the full model does. To use the `ftest` function to compare the models, we need our A matrix and b vector. We see that $$A = \begin{pmatrix}
   0 & 0 & 0 & 0 & 1 & 0 \\
   0 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}$$, and $$b = \begin{pmatrix}
0 \\
0
\end{pmatrix}$$. Our F-statistic is $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q=2 is the difference in dimension between the full and reduced model (ie the number of rows of the A matrix), and n-p is from the full model. We should have q=2 and n-p = 54-6 = 48. Our null distribution is $$F \sim F_{q, n - p}$$. We can use the `ftest` function to calculate the F-statistic.

```{r}
ftest(lm_fit_surgery, matrix(c(0,0,0,0,1,0,0,0,0,0,0,1), byrow = TRUE, nrow = 2, ncol = 6), 0)
```

We see the F-statistic is 0.8545346, which agrees with that determined in the ST503R-3 document. So our p-value is given by $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$. In R we calculate this as follows:

```{r}
1-pf(0.8545346, 2, 48)
```

We see the calculated p-value agrees with the output from the `ftest` function and the ST503R-3 document. The p-value is greater than 0.05, so we fail to reject the null hypothesis at the 5% significance level. That is, we do not have evidence that the full model explains more variability in the response than the reduced model does. 

### Part (e)
Here we consider the reduced model where $$\beta_4 = \beta_5$$. The null hypothesis is that the reduced model explains as much variability in the response as the full model does. To use the `ftest` function to compare the models, we need our A matrix and b vector. In this case we have $$A = \begin{pmatrix}
0 & 0 & 0 & 0 & 1 & -1
\end{pmatrix}$$ and $$b = \begin{pmatrix}
0
\end{pmatrix}$$. Our F-statistic is $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q is the difference in dimension between the full model and the reduced model (ie the number of rows of the A matrix), and n-p comes from the full model. We should have q=1 and n-p = 54-6 = 48. Our null distribution is $$F \sim F_{q, n - p}$$. We can use the `ftest` function to calculate the F-statistic.

```{r}
ftest(lm_fit_surgery, matrix(c(0,0,0,0,1,-1), nrow = 1, ncol = 6), b = 0)
```

We see from the output that our F-statistic is 0.7106423. This matches the F-statistic determined in the ST503R-3 document. Now our p-value is given by $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$. We can calculate this as follows:

```{r}
1-pf(0.7106423, 1, 48)
```

We see that the calculated p-value matches that from both the `ftest` function and the ST503R-3 document. This p-value is greater than 0.05, so we fail to reject the null hypothesis at the 5% significance level. That is, we do not have evidence that the full model explains more variability in the response than the reduced model. 

## Problem 7
For this question we use the commercial property data set. We start by importing the data.

```{r}
property <- read.table('commercial_property_data.txt', header = TRUE)
```

Then we view the structure of the data and the first few rows.

```{r}
str(property)
head(property)
```

Now we fit a regression model with `rental_rates` as the response and the other four variables as predictors.

```{r}
lm_fit_property <- lm(rental_rates ~., data = property)
lm_fit_property |> summary()
```

### Part (a)
The fitted (estimated) regression equation is $$\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1X_1 + \hat{\beta}_2X_2 + \hat{\beta}_3X_3 + \hat{\beta}_4X_4$$, where $$Y = rental \ rates$$
$$X_1 = age$$
$$X_2 = operating \ expenses \ and \ taxes$$
$$X_3 = vacancy \ rates$$
$$X_4 = total \ square \ footage$$

### Part (b)
For this problem we use the output from the model fit summary:

```{r}
lm_fit_property |> summary()
```

The estimated slope for age is -0.142 and is significant at the 0.001 significance level. This means that for every one unit increase in age, we expect, on average, a decrease in rental rates by 0.142 units, assuming all other predictors are held constant. 

The estimated slope for operating expenses and taxes is 0.282 and is significant at the 0.001 significance level. This means that for every one unit increase in operating expenses and taxes, we expect, on average, an increase in rental rates by 0.282 units, assuming all other predictors are held constant. 

The estimated slope for vacancy rates is 0.6193, but it is not significant at the 0.10 significance level or smaller levels. Therefore we do not have evidence that the true value for this slope is different from 0. So we refrain from making any interpretation of the estimate.

The estimated slope for total square footage is 7.924e-06 and is significant at the 0.001 significance level. This means that for every one unit increase in total square footage, we expect, on average, an increase in rental rates by 7.924e-06 units, assuming all other predictors are held constant.

### Part (c)
Here with give the R squared and adjusted R squared values. Since the number of predictors is 4, we have p-1=4, so p=5. And n=81.

```{r}
p <- 5
n <- 81

SSE_property <- t(lm_fit_property$residuals)%*%lm_fit_property$residuals

SST_property <- t(property$rental_rates - mean(property$rental_rates))%*%(property$rental_rates - mean(property$rental_rates))

R_squared_property <- 1-(SSE_property/SST_property)
adj_R_squared_property <- 1-(SSE_property*(n-1)/SST_property/(n-p))

R_squared_property
adj_R_squared_property
```

We see our calculated values for R squared (0.5847496) and adjusted R squared (0.5628943) match those provided in the model fit summary above. 

### Part (d)
Here we conduct a significance test for the null hypothesis that the four regression coefficients for the explanatory variables are all zero. So we have our null hypothesis $$\beta_1 = \beta_2 = \beta_3 = \beta_4 = 0$$ versus the alternative hypothesis that at least one of these beta parameters is non-zero. Under the null hypothesis our F-statistic takes the form $$F_{obs} = \frac{MSR}{MSE}$$ and has null distribution $$F \sim F_{p - 1, n - p}$$, where p-1 is the number of predictors, so p-1=4, meaning p=5. n=81 as the number of observations in the training data, so n-p = 81-5 = 76. We can view the model fit summary to obtain the value of the F-statistic.

```{r}
lm_fit_property |> summary()
```

We see from the output that the value of the F-statistic is 26.76. So our p-value takes the form $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$, which we calculate in R as follows:

```{r}
1-pf(26.76, 4, 76)
```

We obtain a p-value of 7.238654e-14, which is very close to that provided in the model fit summary output, the small difference likely a consequence of differences in floating point arithmetic handling between our calculation and that in the `lm` function. This p-value is much smaller than 0.05, so we reject the null hypothesis at the 5% significance level. That is, we have evidence that at least one beta parameter (for the coefficients) is non-zero. 

### Part (e)
Our null hypothesis is that $$\beta_3 = \beta_4 = 0$$, versus the alternative that at least one of beta3 or beta4 is non-zero. We can formulate this as a general F-test using a reduced model with the linear constraints $$\beta_3 = \beta_4 = 0$$. Then our test statistic is $$F_{obs} = \frac{\frac{SSE_{reduced} - SSE_{full}}{q}}{\frac{SSE_{full}}{n - p}}$$, where q is the difference in dimension between the full and reduced models, and n,p come from the full model. Since we have two linear constraints, q=2. And we know n-p=76 from part (c). Then the null distribution is $$F \sim F_{2, 76}$$. We can determine the F-statistic by fitting the reduced model and using the `anova` function.

```{r}
lm_fit_property_reduced <- lm(rental_rates ~ age + opp_expenses, data = property)
anova(lm_fit_property_reduced, lm_fit_property)
```

We see from the output that our F-statistic is 19.616. The p-value is then given by $$p = P(F \ge F_{obs}) = 1 - P(F < F_{obs})$$. It can be calculated in R as follows:

```{r}
1-pf(19.616, 2, 76)
```

We see that our calculated p-value of 1.352504e-07 agrees with the output in the `anova` function above. Since p is very small, we reject the null hypothesis at the 5% significance level. That is, we have evidence that at least one of beta3 or beta4 is non-zero. In the language of the general F-test, we reject the null hypothesis that the reduced model explains as much of the variability in the response as the full model does. This implies that beta3 and beta4 are unlikely to be simultaneously 0. 

### Part (f)
We repeat the test from part (e) using the `ftest` function. The hypotheses, test statistic, null distribution (including df), and p-value are all the same as in part (e). To conduct the test with the `ftest` function, we need the A matrix and b vector which impose the linear constraint $$A\beta = b$$ onto the parameter vector $$\beta = (\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^T$$. The A matrix is $$A = \begin{pmatrix}
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1
\end{pmatrix}$$, and the b vector is $$b = \begin{pmatrix}
0 \\
0
\end{pmatrix}$$. So now we have all the information we need to use the `ftest` function.

```{r}
ftest(lm_fit_property, matrix(c(0,0,0,0,0,0,1,0,0,1), nrow = 2, ncol = 5), b = 0)
```

We see from the output that we get the same F-statistic, null distribution degrees of freedom (2 and 76), and p-value as we did in part (e). Thus we make the same conclusion as we did in part (e).

### Part (f)




